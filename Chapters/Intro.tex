
\section{Regression Verification}
It is very common that changes in a program introduce new unwanted behavior (`bugs'). Informal methods for checking the new code include code review, testing the new program, and \emph{regression testing}, a method by which the output of the new and old versions of the program are compared on a given set of test cases. Formal methods include program formal verification, which attempts to formally verify the correctness of the new program against user-specified assertions in the code, and formal program equivalence checking. Both problems are undecidable in general. While the general problem of proving equivalence of programs was studied for decades, mostly in the theorem proving world, the specialization of this problem to closely-related programs, coined by  
Godlin and Strichman as \emph{regression verification} \cite{DBLP:conf/dac/GodlinS09}, stirred the development of various tools and approaches, such as RVT~\cite{DBLP:conf/dac/GodlinS09}, Reve~\cite{DBLP:conf/kbse/FelsingGKRU14}, SymDiff~\cite{DBLP:conf/cav/LahiriHKR12} \os{complete list and add references}. Regression verification suggests verifying the program against an older version of itself rather than verifying it against a user-supplied specification or assertions. That is, generate an automated proof of equivalence between a program and its previous version. Although this problem is still undecidable, for closely related programs regression verification is believed to be easier in practice than program verification. It spares the need to manually specify a specification and it can use the similarity between the programs to enable the proof  and to reduce the computational complexity~\cite{DBLP:conf/dac/GodlinS09}. The notion of the verification is weakened that way, as the last version might suffer from the same problems as the new one. Nevertheless, regression verification is relevant in the same places where regression testing is acceptable to ensure the code quality. Specifically, regression verification is most effective when the code has changed but supposes to behave the same toward its interfaces. This is true for \emph{refactoring}, where the code was rewritten to match a certain convention, and it is also true for \emph{performance tuning}. There is more than one definition to what equivalence between program means. In this article we will use the \emph{partial equivalence} notion \cite{DBLP:conf/dac/GodlinS09}. $P_1$ and $P_2$ are partially equivalent if given the same input, terminated executions of both programs yield the same output. Hereon, any reference to equivalence will refer to partial equivalence.

\subsection{Various Approaches to Regression Verification}
We will survey here several techniques that try to cope with the regression verification challenge.

REVE (stands for REgression VErification) \cite{DBLP:conf/kbse/FelsingGKRU14} aims to infer a \emph{coupling predicate} for a pair of programs $P_1$ and $P_2$, which is an invariant that relates $P_1$ and $P_2$ throughout their execution. They steer its generation so it will imply equality of the results in the case where they both terminate. If such a predicate can be inferred, they have proven equivalence between $P_1$ and $P_2$. To do so they compose a predicate containing function summaries, which are expressed as Horn clauses, loop and recursion invariants, and expressions containing the \emph{weakest liberal precondition} ($wlp$). \emph{wp($P,\varphi$)} denotes the weakest condition that needs to hold before an execution of statement list $P$ such that the execution terminates and the postcondition $\varphi$ holds in the final state~\cite{DBLP:journals/cacm/Dijkstra75}. For \emph{wlp($P,\varphi$)}, it demands that $\varphi$ holds after the execution of the program $P$ only if $P$ terminates. The invariants are synthesized automatically. Empirically, when the programs are closely related it is frequently enough to take the equivalence of related variables as the invariant. Then, they exhaustively use \emph{wlp calculus} to reduce the formula to a pure Horn clause. In the end they use a Horn constraint solver, such as Z3 \cite{DBLP:conf/sat/HoderB12} or Eldarica \cite{DBLP:conf/cav/RummerHK13}, to try to prove the equivalence or generate a counterexample if the programs are not equivalent or the proposed invariant is insufficient.

\tool{SYMDIFF} by Microsoft \cite{DBLP:conf/cav/LahiriHKR12} confronts the regression verification challenge from a different angle. Like \tool{REVE}, it is most effective in cases of closely related programs. It concentrates on the \emph{conditional equivalence} notion, which means that two programs are equivalent under a certain input condition. To do so, for each pair of functions it composes a procedure which assumes the input condition, executes both functions and asserts that their results are equal. It then reduces this program to Boogie, an intermediate language developed at Microsoft, and that code is sent to a program verification engine powered by Z3. \tool{SymDiff} also has an operational mode that imitates the one introduced by RVT~\cite{DBLP:conf/dac/GodlinS09}.

\tool{ARDiff} by Badihi at al.~\cite{10.1145/3368089.3409757} is the latest implementation of a regression verification tool based on symbolic execution - Å› a static analysis approach that reasons about program behaviors in terms of symbolic input variables. Noteworthy previous tools are \tool{CLEVER}~\cite{10.1145/3238147.3238178}, \tool{ModDiff}~\cite{10.1007/978-3-319-66706-5_20}, \tool{IMP-S}~\cite{inproceedings} and \tool{DSE}~\cite{10.1145/1453101.1453131}. One of the prominent advantages of using symbolic execution is that it is a top-down approach and therefore it is agnostic to the structure of each program and compare only their symbolic summaries. On the other hand, for programs containing loops and recursions, the number of paths is unlimited (unless given a loop invariant). Because of this, tools such as mentioned above can only prove equivalence up to a certain bound of iterations, and even so the number of paths may be exponential. To ease the verification burden, \tool{ARDiff} uses an abstraction/refinement loop based on CEGAR~\cite{10.1007/10722167_15}. It starts by replacing all syntactically-equal statements on both sides with uninterpreted functions, generates a symbolic summary to each program and uses as SMT-Solver to prove or refute equivalence. If the SMT SOLVER deems the program as non-equivalent, \tool{ARDiff} uses several heuristics to refine the program by restoring some of the abstracted statements and starts the described process again.


Every verification tool such as SeaHorn \cite{DBLP:conf/cav/GurfinkelKKN15}, HSF(C) \cite{DBLP:conf/tacas/GrebenshchikovGLPR12} and Automizer \cite{DBLP:conf/cav/HeizmannHP13}, as well as interactive theorem provers, can be used to prove equivalence between programs. It can be done by generating a new program that executes the given programs with the same non-deterministic input and asserts that their output is equal. However, this route does not take any advantage of the assumed similarity between the compared programs.

\section{Concolic Execution}

\section{Thesis outline}
