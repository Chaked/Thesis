
\section{Regression Verification}
It is very common that changes in program introduce new bugs. There are two dominant methods today aiming to ensure code quality. The first is a manual check of the code by the developer and its colleagues â€“ also known as \emph{code review}. The other method is \emph{regression testing}. The developer creates a set of tests that describes the expected behavior of the program. Then, the code is checked against those tests whenever a new version is introduced. This method is not complete as there might be corner cases the test's writer have missed. Even in the case we have found an anomaly, debugging is usually an expensive action we had rather avoid. Godlin and Strichman have proposed a new approach named \emph{regression verification} \cite{DBLP:conf/dac/GodlinS09}. \emph{Program verification}, the challenge of automatically proving the correctness of a program with respect to a given specification, is an impossible task due to its undecidable nature. It was called a "grand challenge" by Hoare \cite{DBLP:journals/jacm/Hoare03}. Regression verification suggests verifying the program against an older version of itself rather than verifying it against a specification. That is, generate an automated proof of equivalence between a program and its previous version. For closely related programs, regression verification is believed to be easier in practice than program verification. It spares the need to manually specify a specification and it can use the similarity between the programs to reduce computational burden \cite{DBLP:conf/dac/GodlinS09}. The notion of the verification is weakened that way, as the last version might suffer from the same problems as the new one. Nevertheless, regression verification is relevant in the same places where regression testing is acceptable to ensure the code quality. Specifically, regression verification is most effective when the code has changed but supposes to behave the same toward its interfaces. This is true for \emph{refactoring}, where the code was rewritten to match a certain convention, and it's also true for \emph{performance tuning}. One might wonder what equivalence between program means, and this question has several answers indeed. In this article we will use the \emph{partial equivalence} notion \cite{DBLP:conf/dac/GodlinS09}. $P_1$ and $P_2$ are partially equivalent if upon the same input, terminated executions of both programs yield the same output. Hereon, any reference to equivalence will refer to partial equivalence.

\subsection{Various Approaches to Regression Verification}
We will show here several techniques that try to cope with the regression verification challenge.

REVE (stands for REgression VErification) \cite{DBLP:conf/kbse/FelsingGKRU14} aim to infer a coupling predicates for a pair of programs $P_1$ and $P_2$, which is an invariant that relates $P_1$ and $P_2$ throughout their execution. They steer its generation so it will imply equality of the results in the case where they both terminate. If such a predicate can be inferred, they have proven equivalence between $P_1$ and $P_2$. To do so they compose a predicate containing function summaries, which are expressed as Horn clauses, loop and recursion invariants, and expressions containing the \emph{weakest liberal precondition} ($wlp$) notion. the \emph{weakest precondition} was proposed by Dijekstra \cite{DBLP:journals/cacm/Dijkstra75}. \emph{wp($P,\varphi$)} denotes the weakest condition that needs to hold before an execution of statement list $P$ such that the execution terminates and the postcondition $\varphi$ holds in the final state. for \emph{wlp($P,\varphi$)} , it demands $\varphi$ will holds after the execution of the program $P$ only if $P$ terminates. The invariants are synthesized automatically. Empirically, when the programs are closely related it is enough to propose the equivalence of related variables in the context as the invariant. Then, they exhaustively use \emph{wlp calculus} to reduce the formula to a pure Horn clause. In the end they use a Horn constraint solver, such as Z3 \cite{DBLP:conf/sat/HoderB12} or Eldarica \cite{DBLP:conf/cav/RummerHK13}, to prove the equivalence or generate a counter example upon non-equivalence.

SYMDIFF by Microsoft \cite{DBLP:conf/cav/LahiriHKR12} confronts this challenge from a different angle. Like REVE, it is most effective in cases of closely related programs. It concentrates on the \emph{conditional equivalence} notion which means that two programs are equivalent under a certain input condition. To do so, for each pair of functions it composes a procedure which assume the input condition, executes both function and asserts that their results are equal. The functions are flattened by replacing all functions invocations with calls to \emph{uninterpreted functions} (hereon will be referred as $UF$s), which are an abstraction of the original functions. A $UF$ returns a non-deterministic value for each input (sometimes some determinization is applied to preserve consistency). One may notice that a $UF$ is an over approximation of its corresponding function. SYMDIFF handle loops by transforming them to tail-recursive functions. Iteratively, SYMDIFF assumes the functions are equal and try to prove it using the SMT Solver Z3. In the case of failure, it takes the counter example produced by Z3, refines its input condition and try to prove again. It does so until settling on a fixed-point and then it will return the input condition upon it the programs are partial equal.

TODO:Write about tools using symbolic execution such as ModDiff, CLEVER, DSE (Differential Symbolic Execution) and IMP-S (IMPacted Summaries)

It is worth mentioning that every verification tool such as SeaHorn \cite{DBLP:conf/cav/GurfinkelKKN15}, HSF(C) \cite{DBLP:conf/tacas/GrebenshchikovGLPR12} and Automizer \cite{DBLP:conf/cav/HeizmannHP13} can be used to prove equivalence between programs. It can be done by generating a new program which executes the given programs with the same non-deterministic input and asserts that their output is equal. However, this method does not take any advantage of any feature that the regression verification case offers. Both REVE and SYMDIFF perform better on closely related programs because they exploit the similarity to reduce the computational overhead. Since verification techniques run in an exponential complexity, using a regular verification tool without any optimization might yield insufficient results. 

\section{Abstract Interpretation}
Write about Abstract Interpretation

\section{Weakest Precondition}
\label{sec:wp}
Write about Weakest Precondition \cite{10.1145/360933.360975}

\section{Thesis Outline}
